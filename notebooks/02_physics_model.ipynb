{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d509e9d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries loaded successfully\n",
      " NumPy version: 2.3.3\n",
      " Pandas version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Visualization\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\" Libraries loaded successfully\")\n",
    "print(f\" NumPy version: {np.__version__}\")\n",
    "print(f\" Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d99f7-74ef-4b41-b9f4-89848143e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stefan-Boltzman Transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcd9c64-a57c-42ea-be40-fa0d0340b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " StefanBoltzmannTransformer defined\n",
      "   - Mode: 'theoretical_only', 'residual', 'augmented'\n",
      "   - Encodes L = 4πR²σT⁴ as inductive bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class StefanBoltzmannTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes the Stefan-Boltzmann law as an engineered feature and learns\n",
    "    astrophysical corrections (deviations from idealized physics).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mode : str, default='residual'\n",
    "        - 'theoretical_only': Return only SB prediction (baseline)\n",
    "        - 'residual': Learn correction to physics (most interpretable)\n",
    "        - 'augmented': Full feature set with physics guidance\n",
    "    \n",
    "    include_nonlinear : bool, default=True\n",
    "        Add second-order terms for non-blackbody corrections\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    sigma_sb_ : float\n",
    "        Stefan-Boltzmann constant (5.67e-8 W/m²/K⁴)\n",
    "    constant_term_ : float\n",
    "        log₁₀(4πσ) ≈ -6.74\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Input X must have columns: [Temperature(K), Radius(R/Ro), ...]\n",
    "    Assumes solar units for radius (R☉) and absolute luminosity (L☉)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mode='residual', include_nonlinear=True):\n",
    "        self.mode = mode\n",
    "        self.include_nonlinear = include_nonlinear\n",
    "        \n",
    "        # Physical constants\n",
    "        self.sigma_sb_ = 5.670374419e-8  # W m⁻² K⁻⁴\n",
    "        \n",
    "        # Convert to solar units: L☉ = 3.828e26 W, R☉ = 6.96e8 m\n",
    "        # log₁₀(4πσ) for solar units\n",
    "        L_sun = 3.828e26  # watts\n",
    "        R_sun = 6.96e8    # meters\n",
    "        self.constant_term_ = np.log10(4 * np.pi * self.sigma_sb_ * R_sun**2 / L_sun)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"No fitting needed - physics is fixed!\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform stellar parameters into physics-informed features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            First two columns must be Temperature(K) and Radius(R/Ro)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : array-like\n",
    "            Physics-informed features\n",
    "        \"\"\"\n",
    "        # Extract physical parameters\n",
    "        T = X[:, 0]  # Temperature in Kelvin\n",
    "        R = X[:, 1]  # Radius in solar radii\n",
    "        \n",
    "        # Work in log space for numerical stability\n",
    "        log_T = np.log10(T)\n",
    "        log_R = np.log10(R)\n",
    "        \n",
    "        # Theoretical prediction from Stefan-Boltzmann Law\n",
    "        # log(L) = 4*log(T) + 2*log(R) + constant\n",
    "        theoretical_log_L = 4*log_T + 2*log_R + self.constant_term_\n",
    "        \n",
    "        if self.mode == 'theoretical_only':\n",
    "            # Pure physics (no learning)\n",
    "            return theoretical_log_L.reshape(-1, 1)\n",
    "        \n",
    "        elif self.mode == 'residual':\n",
    "            # Learn the CORRECTION to physics\n",
    "            # These features represent \"how much does this star deviate from theory?\"\n",
    "            return np.column_stack([\n",
    "                theoretical_log_L,           # Physics baseline\n",
    "                log_T - np.mean(log_T),      # Temperature anomaly\n",
    "                log_R - np.mean(log_R),      # Radius anomaly\n",
    "            ])\n",
    "        \n",
    "        elif self.mode == 'augmented':\n",
    "            # Full feature set with physics as anchor\n",
    "            features = [\n",
    "                theoretical_log_L,           # Core physics prediction\n",
    "                log_T,                       # Raw temperature\n",
    "                log_R,                       # Raw radius\n",
    "            ]\n",
    "            \n",
    "            if self.include_nonlinear:\n",
    "                # Physically-motivated nonlinear corrections\n",
    "                T_mean = np.mean(log_T)\n",
    "                R_mean = np.mean(log_R)\n",
    "                \n",
    "                features.extend([\n",
    "                    (log_T - T_mean)**2,        # Quadratic T correction\n",
    "                    (log_R - R_mean)**2,        # Quadratic R correction\n",
    "                    (log_T - T_mean)*(log_R - R_mean)  # Interaction\n",
    "                ])\n",
    "            \n",
    "            return np.column_stack(features)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {self.mode}\")\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Return interpretable feature names\"\"\"\n",
    "        if self.mode == 'theoretical_only':\n",
    "            return ['theoretical_log_L']\n",
    "        elif self.mode == 'residual':\n",
    "            return ['theoretical_log_L', 'log_T_anomaly', 'log_R_anomaly']\n",
    "        elif self.mode == 'augmented':\n",
    "            base = ['theoretical_log_L', 'log_T', 'log_R']\n",
    "            if self.include_nonlinear:\n",
    "                base.extend(['log_T²', 'log_R²', 'log_T×log_R'])\n",
    "            return base\n",
    "\n",
    "print(\" StefanBoltzmannTransformer defined\")\n",
    "print(\"   - Mode: 'theoretical_only', 'residual', 'augmented'\")\n",
    "print(\"   - Encodes L = 4πR²σT⁴ as inductive bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdfa915-a46a-401a-b06a-1f04f74bb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncertinity-Aware Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c27dcb-1eec-48bc-b343-30a1d0a5629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AstrophysicalScaler defined\n",
      "   - Handles heteroscedastic measurement errors\n",
      "   - Weights observations by precision\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AstrophysicalScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Scale features by ASTROPHYSICAL UNCERTAINTY, not just statistical spread.\n",
    "    \n",
    "    Standard StandardScaler assumes homoscedastic Gaussian noise.\n",
    "    Real astronomical data has heteroscedastic errors:\n",
    "    - Bright stars measured more precisely than faint ones\n",
    "    - Variable stars have intrinsic scatter\n",
    "    - Systematic errors from distance/extinction uncertainties\n",
    "    \n",
    "    This scaler weights observations by their inverse variance,\n",
    "    giving more influence to high-quality measurements.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uncertainty_aware : bool, default=True\n",
    "        If True and sample_weight provided, compute weighted statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, uncertainty_aware=True):\n",
    "        self.uncertainty_aware = uncertainty_aware\n",
    "        \n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Compute weighted mean and standard deviation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_weight : array-like, optional\n",
    "            Weights for each sample (typically 1/σ² for measurement errors)\n",
    "        \"\"\"\n",
    "        if self.uncertainty_aware and sample_weight is not None:\n",
    "            # Weighted statistics (heteroscedastic)\n",
    "            self.mean_ = np.average(X, axis=0, weights=sample_weight)\n",
    "            self.var_ = np.average((X - self.mean_)**2, axis=0, \n",
    "                                   weights=sample_weight)\n",
    "        else:\n",
    "            # Standard statistics (homoscedastic)\n",
    "            self.mean_ = np.mean(X, axis=0)\n",
    "            self.var_ = np.var(X, axis=0)\n",
    "        \n",
    "        self.scale_ = np.sqrt(self.var_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Standardize features to zero mean and unit variance\"\"\"\n",
    "        return (X - self.mean_) / (self.scale_ + 1e-8)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        \"\"\"Reverse the transformation\"\"\"\n",
    "        return X * self.scale_ + self.mean_\n",
    "\n",
    "print(\"AstrophysicalScaler defined\")\n",
    "print(\"   - Handles heteroscedastic measurement errors\")\n",
    "print(\"   - Weights observations by precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fccac-fdcc-4dbb-9100-3752f842181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c906ff32-01af-4b3d-a285-38b3d3902c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data loaded: (240, 7)\n",
      "\n",
      "Features available:\n",
      "['Temperature(K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)', 'Star type', 'Star color', 'Spectral Class']\n",
      "\n",
      "Star type distribution:\n",
      "Star type\n",
      "0.0    39\n",
      "1.0    40\n",
      "2.0    40\n",
      "3.0    40\n",
      "4.0    40\n",
      "5.0    40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/stars.csv')\n",
    "\n",
    "# Clean column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Handle missing values (simple median imputation for demo)\n",
    "numeric_cols = ['Temperature(K)', 'Luminosity(L/Lo)', 'Radius(R/Ro)', 'Absolute magnitude(Mv)']\n",
    "for col in numeric_cols:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "# Remove any remaining invalid rows\n",
    "data = data.dropna(subset=['Temperature(K)', 'Radius(R/Ro)', 'Luminosity(L/Lo)'])\n",
    "data = data[data['Temperature(K)'] > 0]\n",
    "data = data[data['Radius(R/Ro)'] > 0]\n",
    "data = data[data['Luminosity(L/Lo)'] > 0]\n",
    "\n",
    "print(f\" Data loaded: {data.shape}\")\n",
    "print(f\"\\nFeatures available:\")\n",
    "print(data.columns.tolist())\n",
    "print(f\"\\nStar type distribution:\")\n",
    "print(data['Star type'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f387638-0801-474c-ac63-aeb02fa06d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a79a5a-01e0-4194-9591-efc47b0d159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X): (240, 2)\n",
      "Target (y): (240,)\n",
      "\n",
      "Target statistics (log₁₀ Luminosity):\n",
      "  Min: -4.10\n",
      "  Max: 5.93\n",
      "  Mean: 0.69\n",
      "  Std: 3.91\n"
     ]
    }
   ],
   "source": [
    "X = data[['Temperature(K)', 'Radius(R/Ro)']].values\n",
    "y = np.log10(data['Luminosity(L/Lo)'].values)  # Log-transformed target\n",
    "star_types = data['Star type'].values\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nTarget statistics (log₁₀ Luminosity):\")\n",
    "print(f\"  Min: {y.min():.2f}\")\n",
    "print(f\"  Max: {y.max():.2f}\")\n",
    "print(f\"  Mean: {y.mean():.2f}\")\n",
    "print(f\"  Std: {y.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3735506-d101-4a41-ade2-57d31a1e472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6de91b-ccd6-4cd3-8213-4071dc30eb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARATIVE EXPERIMENT: Physics-Informed vs. Standard ML\n",
      "================================================================================\n",
      "\n",
      "Dataset: 240 stars\n",
      "Cross-validation: 5-fold\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1️  BASELINE: Standard Polynomial Regression (degree=2)\n",
      "   - No physics knowledge\n",
      "   - Black box feature expansion\n",
      "   Test RMSE: 2.6304 ± 0.2470\n",
      "   Test R²:   0.5331 ± 0.0810\n",
      "\n",
      "2️  PURE PHYSICS: Stefan-Boltzmann Prediction Only\n",
      "   - No machine learning\n",
      "   - Shows baseline from theory\n",
      "   RMSE: 1.4030\n",
      "   R²:   0.8711\n",
      "\n",
      "3️  PHYSICS-INFORMED RESIDUAL: Learn Corrections to Theory\n",
      "   - Encodes Stefan-Boltzmann as feature\n",
      "   - Learns astrophysical deviations\n",
      "   - Most interpretable\n",
      "   Test RMSE: 1.3884 ± 0.1971\n",
      "   Test R²:   0.8679 ± 0.0373\n",
      "\n",
      "4️  PHYSICS-INFORMED AUGMENTED: Full Feature Set\n",
      "   - Combines physics + nonlinear terms\n",
      "   - Maximum flexibility\n",
      "   Test RMSE: 1.1954 ± 0.2105\n",
      "   Test R²:   0.9006 ± 0.0313\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def run_comparative_experiment(X, y, cv_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Compare physics-informed vs. standard ML approaches.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Performance metrics for each model\n",
    "    models : dict\n",
    "        Fitted model pipelines\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    models = {}\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPARATIVE EXPERIMENT: Physics-Informed vs. Standard ML\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nDataset: {len(X)} stars\")\n",
    "    print(f\"Cross-validation: {cv_folds}-fold\")\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    \n",
    "    # --- Model 1: Standard Polynomial Regression (Baseline) ---\n",
    "    print(\"\\n1️  BASELINE: Standard Polynomial Regression (degree=2)\")\n",
    "    print(\"   - No physics knowledge\")\n",
    "    print(\"   - Black box feature expansion\")\n",
    "    \n",
    "    poly_pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('regress', Ridge(alpha=1.0))\n",
    "    ])\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        poly_pipeline, X, y, cv=kf,\n",
    "        scoring=['neg_root_mean_squared_error', 'r2'],\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    results['Polynomial'] = {\n",
    "        'train_rmse': -cv_results['train_neg_root_mean_squared_error'].mean(),\n",
    "        'test_rmse': -cv_results['test_neg_root_mean_squared_error'].mean(),\n",
    "        'test_rmse_std': cv_results['test_neg_root_mean_squared_error'].std(),\n",
    "        'train_r2': cv_results['train_r2'].mean(),\n",
    "        'test_r2': cv_results['test_r2'].mean(),\n",
    "        'test_r2_std': cv_results['test_r2'].std(),\n",
    "    }\n",
    "    \n",
    "    # Fit on full data for later analysis\n",
    "    poly_pipeline.fit(X, y)\n",
    "    models['Polynomial'] = poly_pipeline\n",
    "    \n",
    "    print(f\"   Test RMSE: {results['Polynomial']['test_rmse']:.4f} ± {results['Polynomial']['test_rmse_std']:.4f}\")\n",
    "    print(f\"   Test R²:   {results['Polynomial']['test_r2']:.4f} ± {results['Polynomial']['test_r2_std']:.4f}\")\n",
    "    \n",
    "    # --- Model 2: Pure Physics (No Learning) ---\n",
    "    print(\"\\n2️  PURE PHYSICS: Stefan-Boltzmann Prediction Only\")\n",
    "    print(\"   - No machine learning\")\n",
    "    print(\"   - Shows baseline from theory\")\n",
    "    \n",
    "    physics_only = Pipeline([\n",
    "        ('physics', StefanBoltzmannTransformer(mode='theoretical_only')),\n",
    "    ])\n",
    "    \n",
    "    # Compute predictions\n",
    "    y_pred_physics = physics_only.fit_transform(X).flatten()\n",
    "    physics_rmse = np.sqrt(mean_squared_error(y, y_pred_physics))\n",
    "    physics_r2 = r2_score(y, y_pred_physics)\n",
    "    \n",
    "    results['Physics_Only'] = {\n",
    "        'test_rmse': physics_rmse,\n",
    "        'test_r2': physics_r2,\n",
    "    }\n",
    "    models['Physics_Only'] = physics_only\n",
    "    \n",
    "    print(f\"   RMSE: {physics_rmse:.4f}\")\n",
    "    print(f\"   R²:   {physics_r2:.4f}\")\n",
    "    \n",
    "    # --- Model 3: Physics-Informed Residual Learning (OUR INNOVATION) ---\n",
    "    print(\"\\n3️  PHYSICS-INFORMED RESIDUAL: Learn Corrections to Theory\")\n",
    "    print(\"   - Encodes Stefan-Boltzmann as feature\")\n",
    "    print(\"   - Learns astrophysical deviations\")\n",
    "    print(\"   - Most interpretable\")\n",
    "    \n",
    "    physics_residual = Pipeline([\n",
    "        ('physics', StefanBoltzmannTransformer(mode='residual')),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('regress', Ridge(alpha=0.1))\n",
    "    ])\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        physics_residual, X, y, cv=kf,\n",
    "        scoring=['neg_root_mean_squared_error', 'r2'],\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    results['Physics_Residual'] = {\n",
    "        'train_rmse': -cv_results['train_neg_root_mean_squared_error'].mean(),\n",
    "        'test_rmse': -cv_results['test_neg_root_mean_squared_error'].mean(),\n",
    "        'test_rmse_std': cv_results['test_neg_root_mean_squared_error'].std(),\n",
    "        'train_r2': cv_results['train_r2'].mean(),\n",
    "        'test_r2': cv_results['test_r2'].mean(),\n",
    "        'test_r2_std': cv_results['test_r2'].std(),\n",
    "    }\n",
    "    \n",
    "    physics_residual.fit(X, y)\n",
    "    models['Physics_Residual'] = physics_residual\n",
    "    \n",
    "    print(f\"   Test RMSE: {results['Physics_Residual']['test_rmse']:.4f} ± {results['Physics_Residual']['test_rmse_std']:.4f}\")\n",
    "    print(f\"   Test R²:   {results['Physics_Residual']['test_r2']:.4f} ± {results['Physics_Residual']['test_r2_std']:.4f}\")\n",
    "    \n",
    "    # --- Model 4: Physics-Informed Augmented ---\n",
    "    print(\"\\n4️  PHYSICS-INFORMED AUGMENTED: Full Feature Set\")\n",
    "    print(\"   - Combines physics + nonlinear terms\")\n",
    "    print(\"   - Maximum flexibility\")\n",
    "    \n",
    "    physics_augmented = Pipeline([\n",
    "        ('physics', StefanBoltzmannTransformer(mode='augmented', include_nonlinear=True)),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('regress', Ridge(alpha=0.5))\n",
    "    ])\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        physics_augmented, X, y, cv=kf,\n",
    "        scoring=['neg_root_mean_squared_error', 'r2'],\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    results['Physics_Augmented'] = {\n",
    "        'train_rmse': -cv_results['train_neg_root_mean_squared_error'].mean(),\n",
    "        'test_rmse': -cv_results['test_neg_root_mean_squared_error'].mean(),\n",
    "        'test_rmse_std': cv_results['test_neg_root_mean_squared_error'].std(),\n",
    "        'train_r2': cv_results['train_r2'].mean(),\n",
    "        'test_r2': cv_results['test_r2'].mean(),\n",
    "        'test_r2_std': cv_results['test_r2'].std(),\n",
    "    }\n",
    "    \n",
    "    physics_augmented.fit(X, y)\n",
    "    models['Physics_Augmented'] = physics_augmented\n",
    "    \n",
    "    print(f\"   Test RMSE: {results['Physics_Augmented']['test_rmse']:.4f} ± {results['Physics_Augmented']['test_rmse_std']:.4f}\")\n",
    "    print(f\"   Test R²:   {results['Physics_Augmented']['test_r2']:.4f} ± {results['Physics_Augmented']['test_r2_std']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return results, models\n",
    "\n",
    "# Run the experiment\n",
    "results, models = run_comparative_experiment(X, y, cv_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0853f5b-c3bb-46f6-907f-f75c6afb3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Result Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a509de2-4b9f-4e4b-a2f9-793ad5498ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Polynomial', 'Physics Only', 'Physics Residual', 'Physics Augmented'],\n",
    "    'Test RMSE': [\n",
    "        results['Polynomial']['test_rmse'],\n",
    "        results['Physics_Only']['test_rmse'],\n",
    "        results['Physics_Residual']['test_rmse'],\n",
    "        results['Physics_Augmented']['test_rmse']\n",
    "    ],\n",
    "    'Test R²': [\n",
    "        results['Polynomial']['test_r2'],\n",
    "        results['Physics_Only']['test_r2'],\n",
    "        results['Physics_Residual']['test_r2'],\n",
    "        results['Physics_Augmented']['test_r2']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Calculate improvement\n",
    "baseline_rmse = results['Polynomial']['test_rmse']\n",
    "best_physics_rmse = results['Physics_Residual']['test_rmse']\n",
    "improvement = ((baseline_rmse - best_physics_rmse) / baseline_rmse) * 100\n",
    "\n",
    "print(f\"\\n Physics-Informed Improvement: {improvement:.2f}% reduction in RMSE\")\n",
    "\n",
    "# Bar plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "ax = axes[0]\n",
    "colors = ['gray', 'lightblue', 'green', 'darkgreen']\n",
    "bars = ax.bar(comparison_df['Model'], comparison_df['Test RMSE'], \n",
    "              color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Test RMSE (lower is better)', fontweight='bold')\n",
    "ax.set_title('Model Performance: Root Mean Squared Error', fontweight='bold', fontsize=13)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=15, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# R² comparison\n",
    "ax = axes[1]\n",
    "bars = ax.bar(comparison_df['Model'], comparison_df['Test R²'], \n",
    "              color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Test R² (higher is better)', fontweight='bold')\n",
    "ax.set_title('Model Performance: R² Score', fontweight='bold', fontsize=13)\n",
    "ax.set_ylim([0.9, 1.0])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=15, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Plot saved: plots/model_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
